<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Interactive Soundwalk Manual</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <nav class="sidebar">
        <div class="logo">
            <h2>Soundwalk Manual</h2>
            <p>ISO 12913 Compliant</p>
        </div>
        <ul class="nav-menu">
            <li><a href="#intro" class="nav-link active">Introduction</a></li>
            <li><a href="#step1" class="nav-link">Step 1: Planning</a></li>
            <li><a href="#step2" class="nav-link">Step 2: Site Selection</a></li>
            <li><a href="#step3" class="nav-link">Step 3: Conducting the Walk</a></li>
            <li><a href="#step4" class="nav-link">Step 4: Survey (ISO 12913-2 Method A)</a></li>
            <li><a href="#step5" class="nav-link">Step 5: Sound Measurements</a></li>
            <li><a href="#step6" class="nav-link">Step 6: Data Analysis (Soundscapy)</a></li>
            <li><a href="#step7" class="nav-link">Step 7: Psychoacoustic Analysis</a></li>
            <li><a href="#step8" class="nav-link">Step 8: Visualization</a></li>
            <li><a href="#step9" class="nav-link">Step 9: Results & Discussion</a></li>
            <li><a href="#example" class="nav-link">Example Paper</a></li>
        </ul>
    </nav>

    <main class="content">
        <!-- Introduction Section -->
        <section id="intro" class="section active">
            <h1>Professional Soundwalk Training Manual</h1>
            <h2>ISO 12913-2 Based Soundscape Assessment</h2>
            
            <div class="overview-box">
                <h3>What You will Learn</h3>
                <p>The aim of this manual or workflow is to provide understanding or making a start for conducting soundwalks from initial planning through to publishing research papers. Each section tries to include practical guidance and complete, ready-to-use code.</p>
                
                <div class="key-features">
                    <div class="feature">
                        <img src="images/iso_logo.png" alt="ISO Logo" class="feature-icon">
                        <h4>ISO 12913-2 Method A</h4>
                        <p>Complete questionnaire implementation with all questions</p>
                    </div>
                    <div class="feature">
                        <img src="images/soundscapy_logo.png" alt="Soundscapy Logo" class="feature-icon">
                        <h4>Soundscapy Analysis</h4>
                        <p>Standard-compliant data analysis using soundscapy library</p>
                    </div>
                    <div class="feature">
                        <img src="images/psychoacoustic_icon.png" alt="Psychoacoustic Analysis" class="feature-icon">
                        <h4>Psychoacoustic Metrics</h4>
                        <p>Professional analysis of sound measurements</p>
                    </div>
                    <div class="feature">
                        <img src="images/paper_icon.png" alt="Paper Writing" class="feature-icon">
                        <h4>Paper Writing</h4>
                        <p>From results to publication-ready manuscript</p>
                    </div>
                </div>
            </div>

            <div class="workflow-diagram">
                <h3>Complete Workflow</h3>
                <div class="workflow-steps">
                    <div class="workflow-step">1. Plan<br>Survey</div>
                    <div class="arrow">→</div>
                    <div class="workflow-step">2. Select<br>Locations</div>
                    <div class="arrow">→</div>
                    <div class="workflow-step">3. Conduct<br>Walk</div>
                    <div class="arrow">→</div>
                    <div class="workflow-step">4. Administer<br>Survey</div>
                    <div class="arrow">→</div>
                    <div class="workflow-step">5. Measure<br>Sound</div>
                    <div class="arrow">→</div>
                    <div class="workflow-step">6. Analyze<br>Data</div>
                    <div class="arrow">→</div>
                    <div class="workflow-step">7. Visualize<br>Results</div>
                    <div class="arrow">→</div>
                    <div class="workflow-step">8. Write<br>Paper</div>
                </div>
            </div>
        </section>

        <!-- Step 1: Planning -->
        <section id="step1" class="section">
            <h1>Step 1: Planning Your Soundwalk</h1>
            
            <div class="checklist-box">
                <h3>Pre-Study Planning Checklist</h3>
                <ul class="checklist">
                    <li><input type="checkbox"> Define research question</li>
                    <li><input type="checkbox"> Determine number of locations (typically 3-4)</li>
                    <li><input type="checkbox"> Recruit participants (5-20 per walk)</li>
                    <li><input type="checkbox"> Obtain ethics approval (if required)</li>
                    <li><input type="checkbox"> Prepare consent forms</li>
                </ul>
            </div>

            <div class="info-box">
                <h3>Defining Research Questions</h3>
                <p>Start with a clear research objective. Examples:</p>
                <ul>
                    <li><strong>Spatial:</strong> How does soundscape quality vary across different zones in an office?</li>
                    <li><strong>Temporal:</strong> How does soundscape perception change during different times of day?</li>
                    <li><strong>Intervention:</strong> Did the acoustic intervention (if any) improve perceived soundscape quality?</li>
                    <li><strong>Comparison:</strong> How do soundscapes differ between different offices or differently planned offices?</li>
                </ul>
            </div>

            <div class="equipment-box">
                <h3>Equipment Required</h3>
                <div class="equipment-grid">
                    <div class="equipment-item">
                        <h4>Essential</h4>
                        <ul>
                            <li>Sound level meter (Class 1 B&K 2250)</li>
                            <li>Calibrator</li>
                            <li>Printed questionnaires or QR code</li>
                            <li>Clipboards and pens (for notes)</li>
                            <li>Consent forms (if needed or incorporated in the survey)</li>
                        </ul>
                    </div>
                    <div class="equipment-item">
                        <h4>Recommended</h4>
                        <ul>
                            <li>Camera for documentation</li>
                            <li>Floor plans or Location plans</li>
                            <li>Spare batteries, Tripod, Wind screen for the SLM</li>
                        </ul>
                    </div>
                </div>
            </div>
        </section>

        <!-- Step 2: Site Selection -->
        <section id="step2" class="section">
            <h1>Step 2: Selecting Listening Locations</h1>
            
            <div class="location-guide">
                <h3>Location Selection Criteria</h3>
                <p>Choose 3-4 locations that represent different acoustic experiences:</p>
                
                <div class="criteria-grid">
                    <div class="criteria-item">
                        <h4>Diversity</h4>
                        <p>Select locations with different acoustic characteristics, activities and sound sources</p>
                    </div>
                    <div class="criteria-item">
                        <h4>Representativeness</h4>
                        <p>Locations should reflect typical use patterns of the space (helps to validate short term measurements)</p>
                    </div>
                    <div class="criteria-item">
                        <h4>Accessibility</h4>
                        <p>Ensure safe access for all participants</p>
                    </div>
                    <div class="criteria-item">
                        <h4>Safety</h4>
                        <p>Avoid hazardous areas or unstable conditions</p>
                    </div>
                </div>
            </div>

            <div class="example-box">
                <h3>Example: Office Soundwalk (4 Locations)</h3>
                <table class="location-table">
                    <thead>
                        <tr>
                            <th>Location</th>
                            <th>Activity Type</th>
                            <th>Expected Sounds</th>
                            <th>Purpose</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>L1: Open-Plan Area</td>
                            <td>Collaborative work</td>
                            <td>Speech, keyboards, footsteps</td>
                            <td>High-activity workspace</td>
                        </tr>
                        <tr>
                            <td>L2: Focus Room</td>
                            <td>Concentrated work</td>
                            <td>HVAC, minimal speech</td>
                            <td>Quiet work area</td>
                        </tr>
                        <tr>
                            <td>L3: Meeting Room</td>
                            <td>Meetings/calls</td>
                            <td>Speech, presentation equipment</td>
                            <td>Speech-heavy environment</td>
                        </tr>
                        <tr>
                            <td>L4: Break Area</td>
                            <td>Relaxation/social</td>
                            <td>Conversation, coffee machine</td>
                            <td>Social restoration space</td>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <!-- Step 3: Conducting the Walk -->
        <section id="step3" class="section">
            <h1>Step 3: Conducting the Soundwalk</h1>
            
            <div class="procedure-box">
                <h3>ISO 12913-2 Soundwalk Instructions (Section C.3.2.2)</h3>
                <p><strong>Instructions to the participants about to undertake a soundwalk:</strong></p>
                
                <h4>Basic Listening Instructions:</h4>
                <ol class="procedure-list">
                    <li>
                        <strong>Conduct the walk in silence</strong>
                        <p>Pay attention to surrounding sounds and avoid disturbing the concentration of other participants.</p>
                    </li>
                    <li>
                        <strong>Listen to "sound as sound"</strong>
                        <p>Suspend any attempts at "source identification" and source-related value judgements in favour of listening to the innate qualities of the sound.</p>
                    </li>
                    <li>
                        <strong>Identify separate sounds</strong>
                        <p>Try to identify the maximum number of separate sounds audible at any one time.</p>
                    </li>
                    <li>
                        <strong>Natural vs man-made sounds</strong>
                        <p>Identify which sounds are entirely natural and which are man-made and by what or whom.</p>
                    </li>
                </ol>

                <h4>Advanced Listening Instructions (Optional):</h4>
                <p><em>If attention should also be paid to movement, body awareness and sensitization:</em></p>
                <ol class="procedure-list" start="5">
                    <li>
                        <strong>Listen to your body sounds</strong>
                        <p>Listen to the sounds that your body creates while moving. These are the sources of sounds closest to you and establishing the first interaction between you and the environment.</p>
                    </li>
                    <li>
                        <strong>Listen to nearby sounds</strong>
                        <p>Lead your attention away from your own sounds and listen to the sounds nearby.</p>
                    </li>
                    <li>
                        <strong>Listen to distant sounds</strong>
                        <p>Lead your attention away from the nearby sounds and listen beyond, into the distance.</p>
                    </li>
                    <li>
                        <strong>Follow a moving sound</strong>
                        <p>Select a continuous moving sound (e.g. footsteps or a vehicle) and try to listen to it until it becomes inaudible. This can help recalibrate the ear to pick up detail.</p>
                    </li>
                    <li>
                        <strong>Close your eyes when safe</strong>
                        <p>Closing your eyes (when safe to do so) can help to improve listening.</p>
                    </li>
                    <li>
                        <strong>Focus on positive sounds</strong>
                        <p>Try to train your hearing to focus on sounds which have positive associations for you, even if they are only just audible above sounds which normally have negative associations.</p>
                    </li>
                    <li>
                        <strong>Assess environmental effects</strong>
                        <p>Assess how the changing environment alters sounds.</p>
                    </li>
                </ol>
            </div>

            <div class="procedure-box">
                <h3>Standard Procedure at Each Location</h3>
                <ol class="procedure-list">
                    <li>
                        <strong>Arrival (30 seconds):</strong>
                        <p>Guide participants to the location, ask them to stand in a comfortable position</p>
                    </li>
                    <li>
                        <strong>Silent Listening (3 minutes):</strong>
                        <p>Ask participants to listen attentively following the instructions above. Start acoustic measurements simultaneously.</p>
                        <div class="script-box">
                            <em>Script:</em> "Please close your eyes (if safe) and listen carefully to all the sounds around you. Focus on the innate qualities of sound. We will listen for 3 minutes."
                        </div>
                    </li>
                    <li>
                        <strong>Questionnaire (3-5 minutes):</strong>
                        <p>Participants complete the ISO 12913-2 Method A questionnaire while still at the location (For questions refer C.3.1 of ISO 12913-2)</p>
                    </li>
                    <li>
                        <strong>Transition (2-10 minutes):</strong>
                        <p>Move to the next location. Maintain silence or discuss about the current soundscapes during transitions.</p>
                    </li>
                </ol>
            </div>

            <div class="tips-box">
                <h3>Facilitation Tips</h3>
                <ul>
                    <li>Keep the group engaged or focused during transitions</li>
                    <li>Do not suggest what sounds should be pleasant or unpleasant</li>
                    <li>Note any unusual events (construction noise, alarms, etc.)</li>
                    <li>Ensure all participants complete questionnaires before moving</li>
                    <li>Total time per location may be ~10 minutes</li>
                    <li>Total soundwalk duration for 4 locations maybe ~30-50 minutes</li>
                </ul>
            </div>
        </section>

        <!-- Step 4: Survey -->
        <section id="step4" class="section">
            <h1>Step 4: ISO 12913-2 Method A Survey</h1>
            
            <div class="survey-intro">
                <h3>Questionnaire Overview</h3>
                <p>The ISO 12913-2 Method A questionnaire is administered to participants immediately after the 3-minute listening period at each location. The complete questionnaire consists of 6 sections covering perceptual, contextual, and qualitative aspects of soundscape experience.</p>
                <p><strong>All questions and exact wording are provided in ISO 12913-2 Annex C (Section C.3.1).</strong></p>
            </div>

            <div class="info-box">
                <h3>Data Collection Format</h3>
                <p>Collect responses in a structured format (spreadsheet or database) with the following columns:</p>
                <ul>
                    <li><strong>location_id</strong> - Location identifier (L1, L2, L3, etc.)</li>
                    <li><strong>timestamp</strong> - Date and time of response</li>
                    <li><strong>paq_pleasant, paq_chaotic, paq_vibrant, paq_uneventful, paq_calm, paq_annoying, paq_eventful, paq_monotonous</strong> - 8 PAQ attributes (1-5 scale)</li>
                    <li><strong>source_traffic, source_other_noise, source_human, source_natural</strong> - 4 sound sources (1-5 scale)</li>
                    <li><strong>overall_quality</strong> - Overall soundscape quality (1-5 scale)</li>
                    <li><strong>appropriateness</strong> - Appropriateness to place (1-5 scale)</li>
                    <li><strong>sound_standout, sound_negative, sound_positive</strong> - Any Open-ended text responses (optional)</li>
                </ul>
                <p><em>This data structure is compatible with the Soundscapy library used in Step 6 for analysis.</em></p>
            </div>

            <div class="questionnaire-preview">
                <h3>Questionnaire Structure Overview</h3>
                <table class="structure-table">
                    <thead>
                        <tr>
                            <th>Section</th>
                            <th>Questions</th>
                            <th>Scale</th>
                            <th>ISO Reference</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>1. PAQ Attributes</td>
                            <td>8 attributes (pleasant, chaotic, vibrant, uneventful, calm, annoying, eventful, monotonous)</td>
                            <td>1-5 (Strongly disagree -> Strongly agree)</td>
                            <td>ISO 12913-2 Figure C.4</td>
                        </tr>
                        <tr>
                            <td>2. Sound Sources</td>
                            <td>4 main categories (traffic, other noise, human, natural)</td>
                            <td>1-5 (Not at all -> Dominates completely)</td>
                            <td>ISO 12913-2 Figure C.2</td>
                        </tr>
                        <tr>
                            <td>3. Overall Quality</td>
                            <td>1 question</td>
                            <td>1-5 (Very bad -> Very good)</td>
                            <td>ISO 12913-2 Figure C.5</td>
                        </tr>
                        <tr>
                            <td>4. Appropriateness</td>
                            <td>1 question (appropriate to place)</td>
                            <td>1-5 (Not at all -> Perfectly)</td>
                            <td>ISO 12913-2 Figure C.6</td>
                        </tr>
                        <tr>
                            <td>5. Open-ended</td>
                            <td>3 questions (standout sound, negative/positive influences)</td>
                            <td>Text</td>
                            <td>Optional</td>
                        </tr>
                        <tr>
                        </tr>
                    </tbody>
                </table>
            </div>
        </section>

        <!-- Step 5: Sound Measurements -->
        <section id="step5" class="section">
            <h1>Step 5: Acoustic Measurements</h1>
            
            <div class="measurement-guide">
                <h3>Required Acoustic Indicator</h3>
                <p>Measure LAeq at each location during the 3-minute listening period using BK 2250 Sound Level Meter:</p>
                
                <table class="metrics-table">
                    <thead>
                        <tr>
                            <th>Indicator</th>
                            <th>Description</th>
                            <th>Purpose</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>L<sub>Aeq,T</sub></td>
                            <td>Equivalent continuous sound level (A-weighted)</td>
                            <td>Overall sound exposure level during listening period</td>
                        </tr>
                    </tbody>
                </table>
                
                <p><strong>Note:</strong> LAeq is the primary acoustic indicator for soundscape studies (ISO 12913-3, Table D.1). The BK 2250 automatically calculates this during measurement.</p>
            </div>

            <div class="procedure-box">
                <h3>BK 2250 Measurement Protocol</h3>
                <ol>
                    <li><strong>Calibration:</strong> Calibrate BK 2250 before each measurement session using acoustic calibrator</li>
                    <li><strong>Setup:</strong> Set to measure LAeq with Fast time weighting</li>
                    <li><strong>Position:</strong> Place microphone at 1.2-1.5m height (ear level), away from reflective surfaces</li>
                    <li><strong>Timing:</strong> Start measurement when 3-minute listening period begins</li>
                    <li><strong>Duration:</strong> Measure for full 3-minute period (180 seconds)</li>
                    <li><strong>Recording:</strong> Note LAeq value immediately after measurement</li>
                    <li><strong>Documentation:</strong> Record time, location ID, weather or any unusual sound events</li>
                </ol>
            </div>

            <div class="template-box">
                <h3>Measurement Recording Template</h3>
                <pre>
Location ID: _________________    Date: __________    Time: __________

LAeq,3min:    _______ dB(A)

Equipment: BK 2250 Sound Level Meter
Calibration: Verified ☐

Weather conditions (optional): __________________
Any other notes: __________________

Unusual sound events during measurement:
_____________________________________________________________
_____________________________________________________________

Observer: _________________
                </pre>
            </div>
        </section>

        <!-- Step 6: Data Analysis with Soundscapy -->
        <section id="step6" class="section">
            <h1>Step 6: Data Analysis with Soundscapy</h1>
            
            <div class="analysis-intro">
                <h3>Soundscapy: Professional ISO 12913-3 Compliant Analysis</h3>
                <p>Soundscapy is a Python library specifically designed for soundscape analysis following ISO 12913 standards. The tutorials for soundscapy can be found here → <a href="https://soundscapy.readthedocs.io/en/latest/tutorials/" target="_blank">Soundscapy Tutorials</a>. It provides:</p>
                <ul>
                    <li>PAQ circumplex calculation and visualization</li>
                    <li>ISOPleasant and ISOEventful dimensions</li>
                    <li>Statistical comparisons between locations</li>
                    <li>Professional publication-ready plots</li>
                </ul>
            </div>

            <button class="code-toggle" onclick="toggleCode('soundscapy-code')">
                View Complete Soundscapy Analysis Code
            </button>
            
            <div id="soundscapy-code" class="code-container hidden">
                <div class="code-header">
                    <span>Python Implementation - Soundscapy Data Analysis</span>
                    <button onclick="copyCode('soundscapy-code-content')" class="copy-btn">Copy</button>
                </div>
                <pre><code id="soundscapy-code-content">
# File: soundscapy_analysis.py
# Complete Soundscapy-based Analysis for ISO 12913 Soundwalk Data

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from soundscapy import isd
from soundscapy.surveys import preprocessing
from soundscapy.analysis import dimensionality
import scipy.stats as stats

class SoundscapeAnalysis:
    """
    Complete soundscape data analysis using Soundscapy library
    Implements ISO 12913-3 compliant analysis methods
    """
    
    def __init__(self, data_file):
        """
        Initialize analysis with soundwalk data
        
        Parameters:
        -----------
        data_file : str
            Path to CSV file with soundwalk responses
        """
        self.data = pd.read_csv(data_file)
        self.processed_data = None
        self.results = {}
    
    # ====================
    # DATA PREPARATION
    # ====================
    
    def prepare_data(self):
        """
        Prepare data for Soundscapy analysis
        Ensures proper column names and data types
        """
        print("Preparing data for analysis...")
        
        # Check required columns for PAQ
        required_paq = ['pleasant', 'chaotic', 'vibrant', 'uneventful',
                        'calm', 'annoying', 'eventful', 'monotonous']
        
        # If columns have 'paq_' prefix, rename them
        rename_dict = {}
        for col in self.data.columns:
            if col.startswith('paq_'):
                new_name = col.replace('paq_', '')
                rename_dict[col] = new_name
        
        if rename_dict:
            self.data = self.data.rename(columns=rename_dict)
        
        # Verify all PAQ columns exist
        missing = [col for col in required_paq if col not in self.data.columns]
        if missing:
            raise ValueError(f"Missing PAQ columns: {missing}")
        
        # Convert to numeric if needed
        for col in required_paq:
            self.data[col] = pd.to_numeric(self.data[col], errors='coerce')
        
        # Remove any rows with missing PAQ values
        self.processed_data = self.data.dropna(subset=required_paq).copy()
        
        print(f"Data prepared: {len(self.processed_data)} valid responses")
        return self.processed_data
    
    # ====================
    # ISO PLEASANT & ISO EVENTFUL CALCULATION
    # ====================
    
    def calculate_iso_coordinates(self):
        """
        Calculate ISOPleasant and ISOEventful coordinates
        Following ISO 12913-2 circumplex model
        """
        print("Calculating ISO coordinates...")
        
        # Use soundscapy's built-in function
        self.processed_data = isd.add_iso_coords(self.processed_data)
        
        # Also calculate at location level
        location_coords = self.processed_data.groupby('location_id').agg({
            'ISOPleasant': 'mean',
            'ISOEventful': 'mean',
            'pleasant': 'mean',
            'eventful': 'mean',
            'chaotic': 'mean',
            'vibrant': 'mean',
            'calm': 'mean',
            'uneventful': 'mean',
            'annoying': 'mean',
            'monotonous': 'mean'
        }).reset_index()
        
        self.results['location_coords'] = location_coords
        
        print("ISO coordinates calculated")
        print(location_coords[['location_id', 'ISOPleasant', 'ISOEventful']])
        
        return location_coords
    
    # ====================
    # DESCRIPTIVE STATISTICS
    # ====================
    
    def calculate_descriptive_stats(self):
        """
        Calculate comprehensive descriptive statistics for each location
        """
        print("Calculating descriptive statistics...")
        
        paq_cols = ['pleasant', 'chaotic', 'vibrant', 'uneventful',
                    'calm', 'annoying', 'eventful', 'monotonous']
        
        # Group by location
        stats_summary = []
        
        for location in self.processed_data['location_id'].unique():
            loc_data = self.processed_data[self.processed_data['location_id'] == location]
            
            for paq in paq_cols:
                stats_summary.append({
                    'location_id': location,
                    'location_name': loc_data['location_name'].iloc[0],
                    'attribute': paq,
                    'mean': loc_data[paq].mean(),
                    'std': loc_data[paq].std(),
                    'median': loc_data[paq].median(),
                    'min': loc_data[paq].min(),
                    'max': loc_data[paq].max(),
                    'n': len(loc_data)
                })
        
        stats_df = pd.DataFrame(stats_summary)
        self.results['descriptive_stats'] = stats_df
        
        print("Descriptive statistics calculated")
        return stats_df
    
    # ====================
    # STATISTICAL COMPARISONS
    # ====================
    
    def compare_locations(self, attribute='ISOPleasant'):
        """
        Statistical comparison between locations using ANOVA and post-hoc tests
        
        Parameters:
        -----------
        attribute : str
            Attribute to compare (default: 'ISOPleasant')
        """
        print(f"Comparing locations on {attribute}...")
        
        # Prepare data for each location
        groups = []
        location_ids = []
        
        for location in self.processed_data['location_id'].unique():
            loc_data = self.processed_data[self.processed_data['location_id'] == location]
            groups.append(loc_data[attribute].values)
            location_ids.append(location)
        
        # One-way ANOVA
        f_stat, p_value = stats.f_oneway(*groups)
        
        print(f"ANOVA Results for {attribute}:")
        print(f"  F-statistic: {f_stat:.3f}")
        print(f"  p-value: {p_value:.4f}")
        
        if p_value < 0.05:
            print(f"  → Significant difference found (p < 0.05)")
        else:
            print(f"  → No significant difference (p >= 0.05)")
        
        # Store results
        self.results[f'anova_{attribute}'] = {
            'f_statistic': f_stat,
            'p_value': p_value,
            'locations': location_ids
        }
        
        # Pairwise comparisons (t-tests with Bonferroni correction)
        if p_value < 0.05 and len(location_ids) > 2:
            print("\nPairwise comparisons (Bonferroni corrected):")
            n_comparisons = len(location_ids) * (len(location_ids) - 1) / 2
            alpha_corrected = 0.05 / n_comparisons
            
            pairwise_results = []
            
            for i in range(len(location_ids)):
                for j in range(i+1, len(location_ids)):
                    t_stat, p = stats.ttest_ind(groups[i], groups[j])
                    significant = p < alpha_corrected
                    
                    pairwise_results.append({
                        'location1': location_ids[i],
                        'location2': location_ids[j],
                        't_statistic': t_stat,
                        'p_value': p,
                        'significant': significant
                    })
                    
                    sig_marker = "***" if significant else "ns"
                    print(f"  {location_ids[i]} vs {location_ids[j]}: "
                          f"t={t_stat:.3f}, p={p:.4f} {sig_marker}")
            
            self.results[f'pairwise_{attribute}'] = pd.DataFrame(pairwise_results)
        
        return self.results.get(f'anova_{attribute}')
    
    # ====================
    # VISUALIZATION
    # ====================
    
    def plot_circumplex(self, save_path=None):
        """
        Create ISO 12913-2 circumplex plot with location points
        """
        print("Creating circumplex plot...")
        
        fig, ax = plt.subplots(figsize=(10, 10))
        
        # Use soundscapy's built-in circumplex plotting
        isd.circumplex_plot(
            self.processed_data,
            x='ISOPleasant',
            y='ISOEventful',
            hue='location_id',
            ax=ax,
            incl_outline=True
        )
        
        # Add location labels
        for _, row in self.results['location_coords'].iterrows():
            ax.annotate(
                row['location_id'],
                xy=(row['ISOPleasant'], row['ISOEventful']),
                xytext=(5, 5),
                textcoords='offset points',
                fontsize=12,
                fontweight='bold'
            )
        
        plt.title('Soundscape Circumplex - All Locations', fontsize=16, fontweight='bold')
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Circumplex plot saved to {save_path}")
        
        plt.show()
        return fig
    
    def plot_paq_profiles(self, save_path=None):
        """
        Create radar chart showing PAQ profiles for each location
        """
        print("Creating PAQ profile plots...")
        
        paq_attrs = ['pleasant', 'calm', 'vibrant', 'eventful']
        
        # Prepare data
        location_coords = self.results['location_coords']
        
        # Number of variables
        num_vars = len(paq_attrs)
        angles = np.linspace(0, 2 * np.pi, num_vars, endpoint=False).tolist()
        angles += angles[:1]  # Complete the circle
        
        fig, ax = plt.subplots(figsize=(10, 10), subplot_kw=dict(projection='polar'))
        
        # Plot each location
        colors = plt.cm.Set2(np.linspace(0, 1, len(location_coords)))
        
        for idx, (_, location) in enumerate(location_coords.iterrows()):
            values = [location[attr] for attr in paq_attrs]
            values += values[:1]  # Complete the circle
            
            ax.plot(angles, values, 'o-', linewidth=2, 
                   label=location['location_id'], color=colors[idx])
            ax.fill(angles, values, alpha=0.15, color=colors[idx])
        
        # Fix axis labels
        ax.set_xticks(angles[:-1])
        ax.set_xticklabels([attr.capitalize() for attr in paq_attrs], fontsize=12)
        ax.set_ylim(0, 5)
        ax.set_yticks([1, 2, 3, 4, 5])
        ax.set_yticklabels(['1', '2', '3', '4', '5'])
        ax.grid(True)
        
        plt.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1), fontsize=10)
        plt.title('PAQ Profiles by Location', fontsize=16, fontweight='bold', pad=20)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"PAQ profile plot saved to {save_path}")
        
        plt.show()
        return fig
    
    def plot_comparison_bars(self, save_path=None):
        """
        Create bar chart comparing key attributes across locations
        """
        print("Creating comparison bar chart...")
        
        # Select key attributes
        key_attrs = ['ISOPleasant', 'ISOEventful', 'overall_quality']
        
        location_data = self.processed_data.groupby('location_id')[key_attrs].mean().reset_index()
        location_data = location_data.melt(id_vars='location_id', 
                                           value_vars=key_attrs,
                                           var_name='Attribute', 
                                           value_name='Mean Rating')
        
        fig, ax = plt.subplots(figsize=(12, 6))
        
        sns.barplot(data=location_data, x='location_id', y='Mean Rating', 
                   hue='Attribute', ax=ax, palette='Set2')
        
        ax.set_xlabel('Location', fontsize=12, fontweight='bold')
        ax.set_ylabel('Mean Rating', fontsize=12, fontweight='bold')
        ax.set_title('Key Soundscape Attributes by Location', fontsize=14, fontweight='bold')
        ax.set_ylim(0, 5)
        ax.axhline(y=3, color='gray', linestyle='--', alpha=0.5, label='Neutral')
        ax.legend(title='Attribute', fontsize=10)
        ax.grid(axis='y', alpha=0.3)
        
        if save_path:
            plt.savefig(save_path, dpi=300, bbox_inches='tight')
            print(f"Comparison bar chart saved to {save_path}")
        
        plt.show()
        return fig
    
    # ====================
    # COMPREHENSIVE REPORT
    # ====================
    
    def generate_report(self, output_file='soundscape_analysis_report.txt'):
        """
        Generate comprehensive text report of analysis
        """
        print("Generating analysis report...")
        
        with open(output_file, 'w') as f:
            f.write("=" * 80 + "\n")
            f.write("SOUNDSCAPE ANALYSIS REPORT\n")
            f.write("ISO 12913-3 Compliant Analysis using Soundscapy\n")
            f.write("=" * 80 + "\n\n")
            
            # Sample information
            f.write("SAMPLE INFORMATION\n")
            f.write("-" * 80 + "\n")
            f.write(f"Total responses: {len(self.processed_data)}\n")
            f.write(f"Locations: {self.processed_data['location_id'].nunique()}\n")
            f.write(f"Participants: {self.processed_data['participant_id'].nunique()}\n\n")
            
            # Location summary
            f.write("LOCATION SUMMARY - ISO COORDINATES\n")
            f.write("-" * 80 + "\n")
            f.write(self.results['location_coords'][
                ['location_id', 'location_name', 'ISOPleasant', 'ISOEventful']
            ].to_string(index=False))
            f.write("\n\n")
            
            # Descriptive statistics
            f.write("DESCRIPTIVE STATISTICS BY LOCATION\n")
            f.write("-" * 80 + "\n")
            for location in self.processed_data['location_id'].unique():
                loc_stats = self.results['descriptive_stats'][
                    self.results['descriptive_stats']['location_id'] == location
                ]
                f.write(f"\n{location}:\n")
                f.write(loc_stats[['attribute', 'mean', 'std']].to_string(index=False))
                f.write("\n")
            
            f.write("\n" + "=" * 80 + "\n")
        
        print(f"Report saved to {output_file}")
        return output_file


# ====================
# EXAMPLE USAGE
# ====================

if __name__ == "__main__":
    # Example: Complete analysis workflow
    
    # 1. Load and prepare data
    analyzer = SoundscapeAnalysis('soundwalk_data.csv')
    analyzer.prepare_data()
    
    # 2. Calculate ISO coordinates
    analyzer.calculate_iso_coordinates()
    
    # 3. Calculate descriptive statistics
    analyzer.calculate_descriptive_stats()
    
    # 4. Statistical comparisons
    analyzer.compare_locations('ISOPleasant')
    analyzer.compare_locations('ISOEventful')
    
    # 5. Create visualizations
    analyzer.plot_circumplex(save_path='circumplex.png')
    analyzer.plot_paq_profiles(save_path='paq_profiles.png')
    analyzer.plot_comparison_bars(save_path='comparison.png')
    
    # 6. Generate report
    analyzer.generate_report('soundscape_report.txt')
    
    print("\nAnalysis complete!")
                </code></pre>
            </div>
        </section>

        <!-- Continue with remaining steps... -->
        <section id="step7" class="section">
            <h1>Step 7: Psychoacoustic Analysis (Optional)</h1>
            
            <div class="psychoacoustic-intro">
                <h3>Psychoacoustic Metrics from Sound Recordings</h3>
                <p>If you record sound at each location (in addition to measuring LAeq with BK 2250), you can calculate psychoacoustic parameters that correlate with human perception:</p>
                
                <table class="metrics-table">
                    <thead>
                        <tr>
                            <th>Parameter</th>
                            <th>Unit</th>
                            <th>Reference Standard</th>
                            <th>Description</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td>Loudness (N)</td>
                            <td>sone</td>
                            <td>ISO 532-1 (Zwicker)</td>
                            <td>Perceived intensity of sound</td>
                        </tr>
                        <tr>
                            <td>Sharpness (S)</td>
                            <td>acum</td>
                            <td>DIN 45692</td>
                            <td>High-frequency content perception</td>
                        </tr>
                        <tr>
                            <td>Roughness (R)</td>
                            <td>asper</td>
                            <td>Daniel & Weber</td>
                            <td>Perception of amplitude modulation (20-200 Hz)</td>
                        </tr>
                        <tr>
                            <td>Fluctuation Strength (FS)</td>
                            <td>vacil</td>
                            <td>Fastl & Zwicker 2007</td>
                            <td>Perception of slow modulation (0.5-20 Hz, peaks at 4 Hz)</td>
                        </tr>
                        <tr>
                            <td>Psychoacoustic Annoyance (PA)</td>
                            <td>-</td>
                            <td>Zwicker & Fastl</td>
                            <td>Combined annoyance metric: PA = N5(1 + √(W²ₛ + W²_FR))</td>
                        </tr>
                    </tbody>
                </table>
                
                <p><strong>Note:</strong> This analysis requires WAV recordings. The BK 2250 LAeq measurement from Step 5 is sufficient for most soundscape studies. Psychoacoustic analysis provides additional objective correlates of perception. The link for using Mosqito library of python to compute psychoacoustic parameters is here <a href="https://mosqito.readthedocs.io/en/latest/" target="_blank">MoSQITo Documentation</a>.</p>
            </div>

            <button class="code-toggle" onclick="toggleCode('psychoacoustic-code')">
                View Complete Psychoacoustic Analysis Code
            </button>
            
            <div id="psychoacoustic-code" class="code-container hidden">
                <div class="code-header">
                    <span>Python Implementation - Psychoacoustic Analysis (code/psychoacoustic_analysis.py)</span>
                    <button onclick="copyCode('psychoacoustic-code-content')" class="copy-btn">Copy</button>
                </div>
                <pre><code id="psychoacoustic-code-content">
# File: code/psychoacoustic_analysis.py
# Psychoacoustic Analysis - Exact Implementation from ASZ Hospital Study
# Complete analysis of sound recordings using MoSQITo library

# ====================
# REQUIRED LIBRARIES
# ====================
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from mosqito.sq_metrics import loudness_zwst, loudness_zwtv, sharpness_din_from_loudness, roughness_dw
from mosqito.utils import load
import waveform_analysis
from scipy.signal import hilbert
from scipy.interpolate import interp1d

# ====================
# MAIN ANALYSIS FUNCTION
# ====================

def make_psychoacoustic_plot(wav_file, measurement_name):
    """
    Complete psychoacoustic analysis with 5-panel plot.
    
    Calculates and plots:
    - LAeq (A-weighted equivalent level)
    - Loudness (N) - ISO 532-1 Zwicker method
    - Sharpness (S) - DIN 45692
    - Roughness (R) - Daniel & Weber method
    - Fluctuation Strength (FS) - Fastl & Zwicker 2007
    - Psychoacoustic Annoyance (PA)
    
    PA = N(1 + √(W²ₛ + W²_FR))
    where:
      W_S = 0.25(S - 1.75)log₁₀(N)   if S > 1.75, else 0
      W_FR = (2.18/N^0.1)(0.4·FS - 0.6·R)
    
    Returns: dict with all metrics
    """
    sig, fs = load(wav_file)
    
    # Loudness (zwst for mean, zwtv for time-varying plot)
    N, N_specific, bark_axis = loudness_zwst(sig, fs)
    N_tv, N_spec_tv, bark_axis_tv, time_axis = loudness_zwtv(sig, fs)
    
    # Sharpness from specific loudness
    S = sharpness_din_from_loudness(N, N_specific)
    S_tv = sharpness_din_from_loudness(N_tv, N_spec_tv)
    
    # Roughness
    r, r_spec, bark, time_r = roughness_dw(sig, fs, overlap=0)
    
    # Fluctuation Strength (custom implementation)
    FS, time_FS = fluctuation_strength_fastl(sig, fs)
    
    # LAeq calculation
    weighted_signal = waveform_analysis.A_weight(sig, fs)
    # ... (calculate 1-second segments)
    
    # Mean values
    N_mean = N
    S_mean = S
    R_mean = r.mean()
    FS_mean = FS.mean()
    
    # Psychoacoustic Annoyance
    if S_mean > 1.75:
        w_S = 0.25 * (S_mean - 1.75) * np.log10(N_mean)
    else:
        w_S = 0
    w_FR = (2.18 / (N_mean ** 0.1)) * (0.4 * FS_mean - 0.6 * R_mean)
    pa = N_mean * (1 + np.sqrt(w_S**2 + w_FR**2))
    
    # Create 5-panel plot
    fig, ax = plt.subplots(5, 1, figsize=(9, 11))
    # Panel 1: LAeq [dBA]
    # Panel 2: Loudness N [sone]
    # Panel 3: Sharpness S [acum]
    # Panel 4: Roughness R [asper]
    # Panel 5: Fluctuation Strength FS [vacil] with PA annotation
    
    return {
        'Measurement': measurement_name,
        'Loudness_mean': N_mean,
        'Sharpness_mean': S_mean,
        'Roughness_mean': R_mean,
        'FluctuationStrength_mean': FS_mean,
        'PsychoacousticAnnoyance': pa
    }

# ====================
# BATCH PROCESSING
# ====================

def batch_process_measurements(wav_files, output_excel="psychoacoustic_results.xlsx"):
    """Process multiple WAV files and export to Excel"""
    results = []
    for wav_file, measurement_name in wav_files:
        result = make_psychoacoustic_plot(wav_file, measurement_name)
        results.append(result)
    
    df = pd.DataFrame(results)
    df.to_excel(output_excel, index=False)
    print(f"✓ Results exported to {output_excel}")
    return df

# ====================
# EXAMPLE USAGE
# ====================

# Analyze single file
result = make_psychoacoustic_plot("location1.wav", "Location 1")

# Batch process
wav_list = [
    ("location1.wav", "Location 1 - Open Office"),
    ("location2.wav", "Location 2 - Focus Room"),
    ("location3.wav", "Location 3 - Meeting Room"),
    ("location4.wav", "Location 4 - Break Area"),
]
df_results = batch_process_measurements(wav_list)

# Full implementation available in: code/psychoacoustic_analysis.py
                </code></pre>
            </div>
        </section>

        <!-- Step 8: Visualization -->
        <section id="step8" class="section">
            <h1>Step 8: Data Visualization</h1>
            
            <div class="analysis-intro">
                <h3>Standard Visualizations</h3>
                <p>Create comprehensive, standard figures for your soundwalk results:</p>
                <ul>
                    <li>ISO 12913-2 compliant circumplex plots</li>
                    <li>PAQ radar charts for location comparison</li>
                    <li>Sound source dominance visualizations</li>
                    <li>Acoustic-perception relationship plots</li>
                    <li>Floor plan or location plan </li>
                    <li>Other statistical figures needed to answer the research questions</li>
                </ul>
            </div>

            <button class="code-toggle" onclick="toggleCode('visualization-code')">
                View Complete Visualization Code
            </button>
            
            <div id="visualization-code" class="code-container hidden">
                <div class="code-header">
                    <span>Python Implementation - Data Visualization (code/data_visualization.py)</span>
                    <button onclick="copyCode('visualization-code-content')" class="copy-btn">Copy</button>
                </div>
                <pre><code id="visualization-code-content">
# See code/data_visualization.py for complete implementation
# This file contains all professional visualization functions

from data_visualization import SoundwalkVisualization

# Load your data
data = pd.read_csv('soundwalk_data.csv')
acoustic = pd.read_csv('acoustic_measurements.csv')

# Create visualization object
viz = SoundwalkVisualization(data, acoustic)

# Generate all publication-ready figures
viz.create_comprehensive_figure('comprehensive_results.png')
viz.create_report_summary_figure('report_summary.png')
viz.create_floor_plan_heatmap(
    location_coords={'L1': (30, 60), 'L2': (70, 60), 
                     'L3': (30, 30), 'L4': (70, 30)},
    save_path='floor_plan_heatmap.png'
)

# All figures are 300 DPI, journal-ready format
                </code></pre>
            </div>

            <div class="example-box">
                <h3>Example Outputs</h3>
                <p>The visualization module creates standard figures including:</p>
                <ul>
                    <li><strong>Comprehensive Results Figure:</strong> Layout with all key results (circumplex, PAQ comparison, sound sources, acoustic and psychoacoustic correlations)</li>
                    <li><strong>Circumplex Plot:</strong> ISO 12913-2 standard format with quadrant labels and location markers</li>
                    <li><strong>Report Summary:</strong> Summary figures for presentations and reports</li>
                </ul>
            </div>
        </section>

        <!-- Step 9: Results & Discussion -->
        <section id="step9" class="section">
            <h1>Step 9: Results & Discussion</h1>
            
            <div class="analysis-intro">
                <h3>Presenting Your Soundscape Study Results</h3>
                <p>Learn how to analyze, compare and discuss soundscape data across multiple listening points following best practices from published research.</p>
            </div>

            <div class="overview-box">
                <h3>Key Analysis Components</h3>
                <ul>
                    <li><strong>Acoustic & Psychoacoustic Comparison(optional):</strong> Compare SPL, loudness, sharpness, roughness, and fluctuation strength across locations</li>
                    <li><strong>Sound Source Identification:</strong> Analyze which sound sources dominate at each listening point</li>
                    <li><strong>Soundscape Scatter Plots:</strong> Plot ISO Pleasant vs ISO Eventful coordinates for each location</li>
                    <li><strong>Acoustic-Perception Relationships:</strong> Correlate objective measurements with subjective assessments</li>
                    <li><strong>Cross-Location Comparison:</strong> Identify patterns and differences between listening points</li>
                </ul>
            </div>

            <div class="procedure-box">
                <h3>Step 1: Create Summary Tables</h3>
                <p>This is an example paper that uses the similar sound walk approach → <a href="https://www.researchgate.net/publication/377552225_Soundscape_assessment_of_the_School_of_Engineering_external_area_at_the_University_of_Pisa/references" target="_blank">University of Pisa Soundscape Study</a>. Start by organizing all acoustic and psychoacoustic measurements in a comprehensive table:</p>
                
                <h4>Example: Acoustic & Psychoacoustic Indicators Table</h4>
                <table class="metrics-table">
                    <thead>
                        <tr>
                            <th>Metric</th>
                            <th>Point 1</th>
                            <th>Point 2</th>
                            <th>Point 3</th>
                            <th>Point 4</th>
                            <th>Point 5</th>
                        </tr>
                    </thead>
                    <tbody>
                        <tr>
                            <td><strong>SPL</strong></td>
                            <td>66.3 dB</td>
                            <td>80.9 dB</td>
                            <td>66.8 dB</td>
                            <td>65.9 dB</td>
                            <td>69.4 dB</td>
                        </tr>
                        <tr>
                            <td><strong>N<sub>avg</sub></strong></td>
                            <td>10.6 soneGF</td>
                            <td>32.5 soneGF</td>
                            <td>12.6 soneGF</td>
                            <td>15.4 soneGF</td>
                            <td>13.8 soneGF</td>
                        </tr>
                        <tr>
                            <td><strong>L<sub>Aeq,T</sub></strong></td>
                            <td>55.7 dBA</td>
                            <td>73.6 dBA</td>
                            <td>59.4 dBA</td>
                            <td>63.4 dBA</td>
                            <td>60.0 dBA</td>
                        </tr>
                        <tr>
                            <td><strong>L<sub>AF5,T</sub></strong></td>
                            <td>58.9 dBA</td>
                            <td>79.4 dBA</td>
                            <td>63.6 dBA</td>
                            <td>69.0 dBA</td>
                            <td>64.7 dBA</td>
                        </tr>
                    </tbody>
                </table>
                
                <p><strong>Key Points for Table Creation:</strong></p>
                <ul>
                    <li>Include only metrics you want to analyse (not all measured parameters)</li>
                    <li>Highlight extreme values (highest/lowest) to guide attention</li>
                    <li>Use consistent units and decimal places (preferably 2)</li>
                    <li>Add table caption explaining what was measured and when</li>
                </ul>
            </div>

            <div class="procedure-box">
                <h3>Step 2: Analyze Sound Source Dominance</h3>
                <p>Create visualizations showing which sound sources participants identified as dominant at each location:</p>
                
                <h4>Sound Source Categories (ISO 12913-2)</h4>
                <ul>
                    <li><strong>Traffic noise:</strong> Cars, buses, trains, air planes</li>
                    <li><strong>Human sounds:</strong> Conversation, laughter, children at play, footsteps</li>
                    <li><strong>Natural sounds:</strong> Singing birds, flowing water, wind in vegetation</li>
                    <li><strong>Other noise:</strong> Sirens, construction, industry, loading of goods</li>
                </ul>
                
                <p><strong>Visualization Approach:</strong></p>
                <ul>
                    <li>Use stacked bar charts showing frequency distribution of ratings (1-5 scale)</li>
                    <li>Count participants who rated each source type 4 or 5 (dominant/completely dominant)</li>
                    <li>Compare patterns across locations to identify acoustic character</li>
                </ul>
            </div>

            <div class="procedure-box">
                <h3>Step 3: Create Soundscape Scatter Plots</h3>
                <p>Plot each listening point on the ISO Pleasant vs ISO Eventful circumplex:</p>
                
                <h4>Individual Response Plot</h4>
                <p>Plot each participant's response as a single point showing perception variability within one location.</p>
                
                <h4>Average Assessment Plot</h4>
                <p>Plot average coordinates for each listening point to compare overall soundscape character across locations.</p>
                
                <p><strong>Interpretation Guidelines:</strong></p>
                <ul>
                    <li><strong>Quadrant 1 (Vibrant):</strong> High pleasant, high eventful - positive active soundscape</li>
                    <li><strong>Quadrant 2 (Calm):</strong> High pleasant, low eventful - peaceful quiet soundscape</li>
                    <li><strong>Quadrant 3 (Monotonous):</strong> Low pleasant, low eventful - boring uneventful soundscape</li>
                    <li><strong>Quadrant 4 (Chaotic):</strong> Low pleasant, high eventful - negative busy soundscape</li>
                </ul>
            </div>

            <div class="procedure-box">
                <h3>Step 4: Analyze Acoustic-Perception Relationships</h3>
                <p>Investigate how objective measurements relate to subjective assessments:</p>
                
                <h4>Key Relationships to Explore</h4>
                <ul>
                    <li><strong>Loudness vs Sound Quality:</strong> Do higher loudness values correlate with lower perceived quality?</li>
                    <li><strong>Sound Sources vs Perception:</strong> How do different sound source types affect pleasantness?</li>
                    <li><strong>Acoustic Variability vs Eventful:</strong> Does higher N<sub>5</sub>/N<sub>95</sub> indicate more eventful perception?</li>
                    <li><strong>Psychoacoustic Metrics vs PAQ:</strong> How do sharpness, roughness relate to perceived quality?</li>
                </ul>
                
                <p><strong>Statistical Analysis:</strong></p>
                <ul>
                    <li>Calculate correlation coefficients (Pearson or Spearman)</li>
                    <li>Test for significant differences between locations (ANOVA, Kruskal-Wallis)</li>
                    <li>Report p-values and effect sizes</li>
                </ul>
            </div>

            <div class="procedure-box">
                <h3>Step 5: Discussion Framework</h3>
                <p>Structure your discussion to highlight key findings and their implications:</p>
                
                <h4>Discussion Template</h4>
                
                <p><strong>5.1 Main Finding 1: Traffic Noise Dominance</strong></p>
                <p><em>Example from Pisa study:</em> "Road traffic resulted in noise levels above the municipal acoustic classification plan limits (73.6 dBA vs 65 dBA limit). Participants assessed this location as chaotic and unpleasant (ISO Pleasant &lt; 0.25), confirming that traffic noise negatively influences perceived sound quality."</p>
                
                <p><strong>5.2 Main Finding 2: Landscape Influence</strong></p>
                <p><em>Example from Pisa study:</em> "Point 3 (Piazza Manin) and Point 5 (train station) had similar LAeq values (66.8 vs 69.4 dBA), yet Point 3 was rated significantly more pleasant. The presence of architectural landmarks and anthropogenic background noise rather than railway traffic may have reduced negative perception."</p>
                
                <p><strong>5.3 Main Finding 3: Sound Source Type Matters</strong></p>
                <p><em>Example from Pisa study:</em> "Intelligible speech at Point 4 was perceived as more distracting than unintelligible background conversation at Point 3, despite similar overall sound levels. This suggests sound source character influences perception beyond acoustic level."</p>
                
                <p><strong>5.4 Practical Implications</strong></p>
                <ul>
                    <li>Identify specific interventions for each location type</li>
                    <li>Suggest positive sound masking strategies</li>
                    <li>Recommend acoustic zoning or design changes</li>
                    <li>Propose enhancement of pleasant sound sources</li>
                </ul>
                
                <p><strong>5.5 Limitations & Future Work</strong></p>
                <ul>
                    <li>Sample size and participant characteristics (almost always)</li>
                    <li>Temporal limitations (single/ short measurement period)</li>
                    <li>Weather or other parameters not captured</li>
                    <li>Suggestions for longitudinal studies or larger samples</li>
                </ul>
            </div>

            <div class="tips-box">
                <h3>Best Practices for Results & Discussion</h3>
                <ul>
                    <li><strong>Use multiple visualization types:</strong> Tables for precise values, bar charts for comparisons, scatter plots for relationships</li>
                    <li><strong>Reference all figures and tables:</strong> Every visual should be mentioned in the text</li>
                    <li><strong>Compare with literature:</strong> Cite similar studies to contextualize your findings</li>
                    <li><strong>Connect back to objectives:</strong> Ensure discussion addresses all research questions from introduction</li>
                </ul>
            </div>

            <button class="code-toggle" onclick="toggleCode('results-analysis-code')">
                View Results Analysis Code
            </button>
            
            <div id="results-analysis-code" class="code-container hidden">
                <div class="code-header">
                    <span>Python Implementation - Results Analysis (code/results_analysis.py)</span>
                    <button onclick="copyCode('results-analysis-content')" class="copy-btn">Copy</button>
                </div>
                <pre><code id="results-analysis-content">
"""
Results Analysis Script
Creates all figures and tables for your soundscape paper
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats

# Load data
survey_data = pd.read_csv('survey_responses.csv')
acoustic_data = pd.read_csv('acoustic_measurements.csv')
psychoacoustic_data = pd.read_csv('psychoacoustic_metrics.csv')

# 1. CREATE SUMMARY TABLE
def create_summary_table(acoustic_df, psychoacoustic_df):
    """Generate comprehensive metrics table"""
    summary = pd.DataFrame({
        'Location': acoustic_df['location'],
        'SPL (dB)': acoustic_df['spl'],
        'LAeq,T (dBA)': acoustic_df['laeq'],
        'LAF5,T (dBA)': acoustic_df['laf5'],
        'LAF95,T (dBA)': acoustic_df['laf95'],
        'Navg (soneGF)': psychoacoustic_df['loudness_avg'],
        'S (acum)': psychoacoustic_df['sharpness'],
        'R (asper)': psychoacoustic_df['roughness'],
        'FS (vacil)': psychoacoustic_df['fluctuation_strength']
    })
    
    # Highlight extremes
    summary.to_csv('summary_table.csv', index=False)
    print("Summary table saved")
    return summary

# 2. SOUND SOURCE DOMINANCE VISUALIZATION
def plot_sound_source_dominance(survey_df):
    """Create stacked bar chart of sound source ratings"""
    sources = ['traffic_noise', 'human_sounds', 'natural_sounds', 'other_noise']
    locations = survey_df['location'].unique()
    
    fig, ax = plt.subplots(figsize=(12, 6))
    
    for i, loc in enumerate(locations):
        loc_data = survey_df[survey_df['location'] == loc]
        
        # Count ratings 4-5 as dominant
        dominant_counts = []
        for source in sources:
            dominant = ((loc_data[source] == 4) | (loc_data[source] == 5)).sum()
            dominant_counts.append(dominant)
        
        # Plot bars
        x = np.arange(len(sources))
        width = 0.15
        ax.bar(x + i*width, dominant_counts, width, label=loc)
    
    ax.set_xlabel('Sound Source Type', fontsize=12)
    ax.set_ylabel('Number of Participants Rating 4-5', fontsize=12)
    ax.set_title('Sound Source Dominance Across Locations', fontsize=14)
    ax.set_xticks(x + width * 1.5)
    ax.set_xticklabels(['Traffic', 'Human', 'Natural', 'Other'])
    ax.legend()
    plt.tight_layout()
    plt.savefig('sound_source_dominance.png', dpi=300)
    print("Sound source plot saved")

# 3. SOUNDSCAPE SCATTER PLOT
def plot_soundscape_scatter(survey_df):
    """Create ISO Pleasant vs ISO Eventful scatter plot"""
    # Calculate ISO coordinates for each response
    survey_df['iso_pleasant'] = (
        (survey_df['pleasant'] - survey_df['annoying']) / 2
    )
    survey_df['iso_eventful'] = (
        (survey_df['eventful'] - survey_df['uneventful']) / 2
    )
    
    fig, ax = plt.subplots(figsize=(8, 8))
    
    # Plot individual responses
    locations = survey_df['location'].unique()
    colors = plt.cm.Set3(np.linspace(0, 1, len(locations)))
    
    for i, loc in enumerate(locations):
        loc_data = survey_df[survey_df['location'] == loc]
        ax.scatter(loc_data['iso_pleasant'], loc_data['iso_eventful'], 
                  c=[colors[i]], label=loc, s=100, alpha=0.6, edgecolors='black')
    
    # Add quadrant labels
    ax.axhline(0, color='gray', linestyle='--', linewidth=0.8)
    ax.axvline(0, color='gray', linestyle='--', linewidth=0.8)
    
    ax.text(0.6, 0.6, 'Vibrant', fontsize=12, style='italic', color='green')
    ax.text(0.6, -0.6, 'Calm', fontsize=12, style='italic', color='blue')
    ax.text(-0.6, -0.6, 'Monotonous', fontsize=12, style='italic', color='gray')
    ax.text(-0.6, 0.6, 'Chaotic', fontsize=12, style='italic', color='red')
    
    ax.set_xlabel('ISO Pleasant', fontsize=12)
    ax.set_ylabel('ISO Eventful', fontsize=12)
    ax.set_title('Soundscape Scatter Plot', fontsize=14)
    ax.set_xlim(-1, 1)
    ax.set_ylim(-1, 1)
    ax.legend(loc='upper left')
    ax.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig('soundscape_scatter.png', dpi=300)
    print("Scatter plot saved")

# 4. ACOUSTIC-PERCEPTION CORRELATION
def analyze_correlations(survey_df, acoustic_df):
    """Analyze relationships between acoustic and perception data"""
    # Merge datasets
    merged = pd.merge(survey_df, acoustic_df, on='location')
    
    # Calculate overall assessment
    merged['sound_quality'] = merged[['pleasant', 'calm', 'vibrant']].mean(axis=1)
    
    # Correlations
    print("\n=== ACOUSTIC-PERCEPTION CORRELATIONS ===")
    print(f"LAeq vs Sound Quality: r = {merged['laeq'].corr(merged['sound_quality']):.3f}")
    print(f"Loudness vs Sound Quality: r = {merged['loudness_avg'].corr(merged['sound_quality']):.3f}")
    
    # Plot
    fig, axes = plt.subplots(1, 2, figsize=(12, 5))
    
    axes[0].scatter(merged['laeq'], merged['sound_quality'])
    axes[0].set_xlabel('LAeq,T (dBA)')
    axes[0].set_ylabel('Average Sound Quality (1-5)')
    axes[0].set_title('Noise Level vs Perceived Quality')
    
    axes[1].scatter(merged['loudness_avg'], merged['sound_quality'])
    axes[1].set_xlabel('Average Loudness (soneGF)')
    axes[1].set_ylabel('Average Sound Quality (1-5)')
    axes[1].set_title('Loudness vs Perceived Quality')
    
    plt.tight_layout()
    plt.savefig('acoustic_perception_correlation.png', dpi=300)
    print("Correlation plots saved")

# 5. STATISTICAL COMPARISON BETWEEN LOCATIONS
def statistical_comparison(survey_df):
    """Compare locations statistically"""
    locations = survey_df['location'].unique()
    
    print("\n=== STATISTICAL COMPARISONS ===")
    
    # Kruskal-Wallis test (non-parametric)
    location_groups = [survey_df[survey_df['location'] == loc]['pleasant'] 
                      for loc in locations]
    h_stat, p_value = stats.kruskal(*location_groups)
    
    print(f"Kruskal-Wallis H-statistic: {h_stat:.3f}")
    print(f"p-value: {p_value:.4f}")
    
    if p_value < 0.05:
        print("Significant difference between locations (p < 0.05)")
    else:
        print("No significant difference between locations")

# RUN ALL ANALYSES
if __name__ == "__main__":
    print("Starting results analysis...")
    
    # Load your data files
    survey = pd.read_csv('survey_responses.csv')
    acoustic = pd.read_csv('acoustic_measurements.csv')
    psychoacoustic = pd.read_csv('psychoacoustic_metrics.csv')
    
    # Generate all outputs
    summary_table = create_summary_table(acoustic, psychoacoustic)
    plot_sound_source_dominance(survey)
    plot_soundscape_scatter(survey)
    analyze_correlations(survey, acoustic)
    statistical_comparison(survey)
    
    print("\nAll analyses complete! Check output files.")
                </code></pre>
            </div>
        </section>

        <!-- Example Paper Reference -->
        <section id="example" class="section">
            <h1>Example Paper: University of Pisa Soundscape Study</h1>
            
            <div class="overview-box">
                <h3>Complete Published Example</h3>
                <p><strong>Title:</strong> Soundscape Assessment of the School of Engineering External Area at the University of Pisa</p>
                <p><strong>Authors:</strong> Paolo Croce, Francesco Leccese, Giacomo Salvadori, Chiara Bartalucci, Francesco Borchi, Paola Pulella</p>
                <p><strong>Conference:</strong> 10th Convention of the European Acoustics Association, Turin, Italy (2023)</p>
                <p><strong>DOI:</strong> 10.61782/fa.2023.0854</p>
            </div>

            <div class="info-box">
                <h3>Full Paper Available</h3>
                <p>The complete PDF of this example paper is included with this manual:</p>
                <p><strong>File location:</strong> <code>SoundWalk Example paper.pdf or <a href="https://www.researchgate.net/publication/377552225_Soundscape_assessment_of_the_School_of_Engineering_external_area_at_the_University_of_Pisa/references" target="_blank">University of Pisa Soundscape Study</a>.</p>
                </code></p>
                <p>This paper demonstrates all the concepts covered in this manual applied to a real urban soundscape study.</p>
            </div>

            <div class="procedure-box">
                <h3>Study Overview</h3>
                
                <h4>Study Site</h4>
                <p>Area between Pisa San Rossore train station, Piazza del Duomo and the School of Engineering. This is a compact 15-minute walking area with diverse acoustic environments.</p>
                
                <h4>Participants</h4>
                <ul>
                    <li>18 engineering students familiar with acoustics concepts</li>
                    <li>83% aged 20-35, regular visitors to study area</li>
                    <li>Participated after soundscape seminar in Lighting and Applied Acoustics course</li>
                </ul>
                
                <h4>Measurement Details</h4>
                <ul>
                    <li><strong>Date:</strong> November 28, 2022, 11:30 AM - 1:30 PM</li>
                    <li><strong>Weather:</strong> Overcast, 6-10°C, no rain</li>
                    <li><strong>Equipment:</strong> HEAD Acoustics Binaural Sensor Unit Code 1508</li>
                    <li><strong>Duration:</strong> 3 minutes per listening point</li>
                    <li><strong>Method:</strong> ISO/TS 12913-2:2018 Method A</li>
                </ul>
            </div>

            <div class="procedure-box">
                <h3>Five Listening Points</h3>
                
                <h4>Point 1: School of Engineering Main Entrance</h4>
                <ul>
                    <li>SPL: 66.3 dB | LAeq: 55.7 dBA | Loudness: 10.6 soneGF</li>
                    <li>Baseline university environment</li>
                </ul>
                
                <h4>Point 2: Via Bonanno Pisano (Busiest Street)</h4>
                <ul>
                    <li>SPL: 80.9 dB | LAeq: 73.6 dBA | Loudness: 32.5 soneGF</li>
                    <li>Traffic noise completely dominant (53% of participants use daily)</li>
                    <li>Rated as chaotic, unpleasant, dynamic</li>
                    <li><strong>Exceeded municipal noise limits</strong> (73.6 vs 65 dBA limit)</li>
                </ul>
                
                <h4>Point 3: Piazza Daniele Manin (Gateway to Piazza del Duomo)</h4>
                <ul>
                    <li>SPL: 66.8 dB | LAeq: 59.4 dBA | Loudness: 12.6 soneGF</li>
                    <li>Anthropogenic activities rated as vibrant</li>
                    <li>Positive assessment despite similar levels to Point 5</li>
                </ul>
                
                <h4>Point 4: Tower of Pisa</h4>
                <ul>
                    <li>SPL: 65.9 dB | LAeq: 63.4 dBA | Loudness: 15.4 soneGF</li>
                    <li>Tourist area with intelligible speech</li>
                    <li>Slightly lower pleasantness than Point 3 (3.11 vs 3.58)</li>
                </ul>
                
                <h4>Point 5: Pisa San Rossore Train Station</h4>
                <ul>
                    <li>SPL: 69.4 dB | LAeq: 60.0 dBA | Loudness: 13.8 soneGF</li>
                    <li>Railway traffic influence</li>
                    <li>Rated less pleasant than Point 3 despite similar dBA</li>
                </ul>
            </div>

            <div class="procedure-box">
                <h3>Key Findings</h3>
                
                <h4>Finding 1: Traffic vs Architectural Context</h4>
                <p>Point 2 (busy street) had significantly higher noise levels and was rated as chaotic/unpleasant. Road traffic negatively influenced perception and exceeded regulatory limits.</p>
                
                <h4>Finding 2: Visual Landscape Influence</h4>
                <p>Points 3 and 5 had similar LAeq (66.8 vs 69.4 dBA), but Point 3 near architectural landmarks was rated more pleasant. Visual context moderated negative perception of similar sound levels.</p>
                
                <h4>Finding 3: Sound Source Character Matters</h4>
                <p>Anthropogenic sounds were assessed differently based on character: unintelligible background noise (Point 3) was more pleasant than intelligible speech (Point 4). Sound type, not just level, influences perception.</p>
                
                <h4>Finding 4: Loudness Correlates with Quality</h4>
                <p>Lower noise levels generally associated with more positive sound quality assessment, but relationship moderated by sound source type and visual environment.</p>
            </div>

            <div class="procedure-box">
                <h3>Intervention Recommendations</h3>
                
                <h4>Point 2 (Busy Street) - Classical Noise Reduction</h4>
                <ul>
                    <li>Traffic management to reduce vehicle volumes</li>
                    <li>Speed reduction measures</li>
                    <li>Acoustic barriers or green buffers</li>
                    <li>Introduction of positive sound masking</li>
                </ul>
                
                <h4>Point 5 (Train Station) - Soundscape Enhancement</h4>
                <ul>
                    <li>Add areas for social interaction</li>
                    <li>Commercial activities to create pleasant anthropogenic background</li>
                    <li>Visual improvements to shift perception</li>
                    <li>Positive sound elements (water features, vegetation)</li>
                </ul>
            </div>

            <div class="tips-box">
                <h3>What You Can Learn from This Paper</h3>
                <ul>
                    <li><strong>Study Design:</strong> How to plan a compact urban soundwalk with diverse acoustic environments</li>
                    <li><strong>Data Presentation:</strong> Effective use of tables, scatter plots and bar charts</li>
                    <li><strong>Results Integration:</strong> Combining acoustic measurements, psychoacoustic metrics and perceptual data</li>
                    <li><strong>Discussion Structure:</strong> Linking findings to practical interventions</li>
                    <li><strong>Regulatory Context:</strong> Comparing results to municipal noise classification plans</li>
                    <li><strong>Limitations:</strong> Acknowledgment of short measurement periods and sample characteristics</li>
                </ul>
            </div>

            <div class="example-box">
                <h3>Adapting This Approach to Your Study</h3>
                <p>Use this paper as a template for your own soundscape research:</p>
                <ul>
                    <li>Similar compact study area (15-minute walking distance)</li>
                    <li>3-4 measurement points with diverse acoustic characters</li>
                    <li>3-minute measurements per point</li>
                    <li>ISO 12913-2 Method A questionnaire</li>
                    <li>Comprehensive acoustic and psychoacoustic measurements</li>
                    <li>Soundscape Scatter Plot analysis</li>
                    <li>Location-specific intervention recommendations</li>
                </ul>
            </div>
        </section>
        
    </main>

    <script src="script.js"></script>
</body>
</html>